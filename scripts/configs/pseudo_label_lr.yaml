datasets:
  # - name: bdd
  #   # categories:
  #   #   - trailer
  #   #   - train
  #   # - wheelchair
  # - name: coco
  # - name: lvis
  - name: objectnet
    #subset: small_sample
    #subset: class_subset2
    categories:
      - eyeglasses
      - egg carton
      - combination lock
      - soap bar
      - air freshener
      - kettle
      - ziploc bag
      - bicycle
      - power cable
      - dress shoe (men)
      - paperclip
      - orange
      - watch
      - cd case
      - tie
      - safety pin
      - lettuce
      - bucket
      - ladle
      - envelope
      - toilet paper roll
      - coffee table
      - razor
      - suitcase
      - lampshade
      - document folder (closed)
      - paper plates
      - soap bar
      - whistle
      - bread knife
      - mixing / salad bowl
      - padlock
      - stopper (sink/tub)
      - poster
      - contact lens case
shared_session_params: # see SessionParams
  batch_size: 1 
  shortlist_size: 50
  index_options: 
    use_vec_index: False # for bdd and coco.
  index_spec : 
      i_name: multiscalemed
      # c_name: small_sample
#      i_name: multiscalecoarse
      # i_name: coarse
  agg_method: plain_score
  # agg_method: avg_score
  aug_larger: greater
shared_bench_params: # see BenchParams
  max_feedback: null
  box_drop_prob: 0. 
  max_results: 10 # max positive results
  n_batches : 30 # max batches
  provide_textual_feedback: False
  query_template : "a {}"
variants:
    # - name: lknn
    #   max_samples: 20
    #   interactive: lknn
    #   start_policy: after_first_positive
    #   interactive_options:
    #     gamma: .1
    #     use_clip_as_gamma: True
    #     matrix_options:
    #       knn_path: nndescent10
    #       self_edges : False
    #       symmetric: False
    #       normalized_weights : False
    #       knn_k: 
    #         choose: [5]
    #       edist: 
    #         choose: [.05]
    #         # choose: [1.6]
    #         # choose: [.05]
    #         # choose: [.00075,  .00625, .2, .4, 3.2]
    #         # choose: [.05]
    #         # choose: [0.00038, .00075, 3.2]
    #         # choose: [.05]
    #     normalize_scores : False
    #     sigmoid_before_propagate: True  
    #     calib_a: 
    #       choose: [10.]
    #     calib_b: 
    #       choose: [-0.4]
    #     prior_weight: 
    #       choose: [0.] # good for unnormalized
    # - name: active_search_l0
    #   max_samples: 20
    #   interactive: active_search
    #   start_policy: after_first_positive
    #   interactive_options:
    #     gamma: .1
    #     use_clip_as_gamma: True
    #     implementation: 
    #       choose: [vectorized, loop]
    #     lookahead: 1
    #     time_horizon: 30 # make equal to n_batches
    #     pruning_on: True # makes no difference for lookahead 0
    #     matrix_options:
    #       knn_path: nndescent10
    #       self_edges : False
    #       normalized_weights : False
    #       symmetric: False
    #       knn_k: 
    #         choose: [5]
    #       edist: 
    #         choose: [.05]
    #         # choose: [1.6]
    #         # choose: [.05]
    #         # choose: [.00075,  .00625, .2, .4, 3.2]
    #         # choose: [.05]
    #         # choose: [0.00038, .00075, 3.2]
    #         # choose: [.05]
    #     normalize_scores : False
    #     sigmoid_before_propagate: True  
    #     calib_a: 
    #       choose: [10.]
    #     calib_b: 
    #       choose: [-0.4]
    #     prior_weight: 
    #       choose: [0.] # good for unnormalized
    - name: active_search_l1
      max_samples: 20
      interactive: active_search
      start_policy: after_first_positive
      interactive_options:
        implementation: 
          #vectorized
          choose: [vectorized, loop]
        lookahead: 2
        pruning_on: False
        gamma: .1
        use_clip_as_gamma: True
        time_horizon: 9
        matrix_options:
          knn_path: nndescent10
          symmetric: False
          self_edges : False
          normalized_weights : False
          knn_k: 
            choose: [5]
          edist: 
            choose: [.05]
            # choose: [1.6]
            # choose: [.05]
            # choose: [.00075,  .00625, .2, .4, 3.2]
            # choose: [.05]
            # choose: [0.00038, .00075, 3.2]
            # choose: [.05]
        normalize_scores : False
        sigmoid_before_propagate: True  
        calib_a: 
          choose: [10.]
        calib_b: 
          choose: [-0.4]
        prior_weight: 
          choose: [0.] # good for unnormalized
    # - name: active_search_l1
    #   max_samples: 20
    #   interactive: active_search
    #   start_policy: after_first_positive
    #   interactive_options:
    #     lookahead: 2
    #     time_horizon: 30 # make equal to n_batches
    #     pruning_on: False
    #     matrix_options:
    #       knn_path: nndescent60
    #       symmetric : False
    #       self_edges : False
    #       normalized_weights : False
    #       knn_k: 
    #         choose: [10]
    #       edist: 
    #         choose: [.05]
    #         # choose: [1.6]
    #         # choose: [.05]
    #         # choose: [.00075,  .00625, .2, .4, 3.2]
    #         # choose: [.05]
    #         # choose: [0.00038, .00075, 3.2]
    #         # choose: [.05]
    #     normalize_scores : False
    #     sigmoid_before_propagate: True  
    #     calib_a: 
    #       choose: [10.]
    #     calib_b: 
    #       choose: [-0.4]
    #     prior_weight: 
    #       choose: [0.] # good for unnormalized
    # - name: baseline
    #   interactive: plain
    # - name: log_reg2
    #   max_samples: 10
    #   interactive: log_reg2
    #   interactive_options:
    #     class_weights: 
    #       choose: [1.]
    #     scale: centered
    #     reg_lambda: 
    #       choose: [.25] #, .5, 1., 2., 4., 8., 16., 32.]
    #       # choose: [4.]
    #     max_iter: 200.
    #     lr: 1.
    #     fit_intercept: false
#     - name: pseudo_lr_switch # change to use new config
#       max_samples: 20
#       interactive: pseudo_lr
#       interactive_options:
#         switch_over: True
#         real_sample_weight: 
#           choose: [1.]
#         sample_size: 
#           choose : [10000]
#         log_reg_params:
#           class_weights: 
#             choose: [1.]
#           scale: centered
#           reg_lambda: 
#             # choose: [.25, .5, 1., 2.]
#             choose : [1.]
#           max_iter: 200.
#           lr: 1
#           fit_intercept: False
#         label_prop_params:
#           matrix_options:
#             knn_path: nndescent10
#             self_edges : False
#             normalized_weights : False
#             knn_k: 
#               choose: [10]
#             edist: 
# #              choose: [.2, .1, .05] # should you use a lower prop for negatives and a larger for positives?
#               choose: [.05]
#           normalize_scores : False
#           sigmoid_before_propagate: True  
#           calib_a: 
#             choose: [10.]
#           calib_b: 
#             choose: [-0.4]
#           prior_weight: 
#             choose: [1.] # good for unnormalized
    # - name: knn_prop2
    #   max_samples: 20
    #   interactive: knn_prop2
    #   interactive_options:
    #     matrix_options:
    #       knn_path: nndescent10
    #       self_edges : False
    #       symmetric: True
    #       normalized_weights : False
    #       knn_k: 
    #         choose: [10]
    #       edist: 
    #         #choose: [.00625, .0125, .025, .05, .1, .2, .4, .8, 1.6]
    #         # choose: [1.6]
    #         choose: [.05]
    #         # choose: [.00075,  .00625, .2, .4, 3.2]
    #         # choose: [.05]
    #         # choose: [0.00038, .00075, 3.2]
    #         # choose: [.05]
    #     normalize_scores : False
    #     sigmoid_before_propagate: True  
    #     calib_a: 
    #       choose: [10.]
    #     calib_b: 
    #       choose: [-0.4]
    #     prior_weight: 
    #       choose: [1.] # good for unnormalized
